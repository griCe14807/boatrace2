{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ボートレースのレース情報をクロールしpickleファイルに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from http.client import RemoteDisconnected\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. モジュールをロード\n",
    "### 1.1 web pageから情報を取ってきてpandas dfに格納するモジュール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 レース結果のページからスクレイプするモジュール\n",
    "- 例：https://boatrace.jp/owpc/pc/race/raceresult?rno=11&jcd=15&hd=20210224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "def scrape_beforeinfo(soup, rno, jcd, hd):   \n",
    "    # 展示競争のコース・スタートタイムをクロール\n",
    "    race_result_dict_list_2 = []\n",
    "    exhibition_start_rows = soup.find(class_=\"is-w238\").find(class_=\"is-p10-0\").find_all(\"tr\")\n",
    "    \n",
    "    for i, exhibition_start_row in enumerate(exhibition_start_rows, 1):\n",
    "        race_result_dict_2 = {\"date\": \"-\".join([hd[0:4], hd[5:7], hd[8:10]]),\n",
    "                        \"venue\": jcd,\n",
    "                        \"raceNumber\": rno[:-1]\n",
    "                        }\n",
    "\n",
    "        race_result_dict_2[\"exhibition_cource\"] = i\n",
    "        race_result_dict_2[\"枠\"] = int(exhibition_start_row.find(class_=re.compile(\"table1_boatImage1Number\")).text)\n",
    "        race_result_dict_2[\"exhibition_start_time\"] = exhibition_start_row.find(class_=\"table1_boatImage1Time\").text\n",
    "        \n",
    "        race_result_dict_list_2.append(race_result_dict_2)\n",
    "    \n",
    "    # dictを入れたlistをdfに変換\n",
    "    beforeinfo_df = pd.DataFrame.from_dict(race_result_dict_list_2)\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "\n",
    "    return beforeinfo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 そのほかcrawl, scrapeに必要なモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_url(crawl_key, rno, jcd, hd):\n",
    "    \"\"\"\n",
    "    :param crawl_key: 何をcrawleするか。選択肢は、\"odds3t\"（オッズ）, \"racelist\"(出走表）,\n",
    "    \"beforeinfo\" (直前情報）もしくは\"raceresult\" (レース結果)\n",
    "    :param rno: レース番号。8Rなど、1-12の数字 + R をstrで\n",
    "    :param jcd: 会場名。\"桐　生\"、\"びわこ\"など\n",
    "    :param hd: holding day (レース開催日)、2019/03/28などyyyy/mm/ddの形で入力（strで）\n",
    "    :return dds_url: 公式サイト最終オッズが書かれているページのurl. これを使ってcrawlする\n",
    "    \"\"\"\n",
    "    jcd_dict =  {\"桐　生\": \"01\", \"戸　田\": \"02\", \"江戸川\": \"03\", \"平和島\": \"04\", \"多摩川\": \"05\", \"浜名湖\": \"06\", \"蒲　郡\": \"07\", \"常　滑\": \"08\",\n",
    "                \"　津　\": \"09\", \"三　国\": \"10\", \"びわこ\": \"11\", \"住之江\": \"12\", \"尼　崎\": \"13\", \"鳴　門\": \"14\", \"丸　亀\": \"15\", \"児　島\": \"16\",\n",
    "                \"宮　島\": \"17\", \"徳　山\": \"18\", \"下　関\": \"19\", \"若　松\": \"20\", \"芦　屋\": \"21\", \"福　岡\": \"22\", \"唐　津\": \"23\", \"大　村\": \"24\"\n",
    "                }\n",
    "    rno = rno[:-1]\n",
    "    hd = hd[0:4] + hd[5:7] + hd[8:10]\n",
    "\n",
    "    odds_url = \"http://boatrace.jp/owpc/pc/race/\" + crawl_key + \"?rno=\" + rno + \"&jcd=\" + jcd_dict[jcd] + \"&hd=\" + hd\n",
    "\n",
    "    return odds_url\n",
    "\n",
    "\n",
    "def html_parser(site_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        request = urllib.request.Request(url=site_url, headers=headers)\n",
    "        response = urllib.request.urlopen(request)\n",
    "\n",
    "        html = response.read().decode('utf-8')\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # データベース作成の際、remotedisconnectedになった場合,そのレースをパス\n",
    "    except RemoteDisconnected:\n",
    "        print(\"remote disconnected error !\")\n",
    "        return None\n",
    "\n",
    "    except ConnectionResetError:\n",
    "        print(\"Connection Reset error !\")\n",
    "        return None\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 実行\n",
    "- 最初の以下の行にてクロールを行う日付を指定\n",
    "\n",
    "　　　　　　　　`　hd_list = [\"2021/02/0\" + str(day) for day in range(1,10)]`\n",
    "- クロール元：ボートレース 公式サイト（https://boatrace.jp/owpc/pc/race/racelist?rno=12&jcd=01&hd=20210325など）\n",
    "- 保存先：'./crawledData/　以下。日にちごとにファイルを作成し保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0日分のデータが未収集\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "race_file_set = set([os.path.basename(file) for file in glob.glob(os.path.join('../../../data/crawledData', '*.pkl'))])\n",
    "start_time_file_set = set([os.path.basename(file) for file in glob.glob(os.path.join('../../../data/crawledData/exhibition_mod', '*.pkl'))])\n",
    "\n",
    "diff_file_name_list = list(race_file_set - start_time_file_set)\n",
    "hd_list = [filename[0:4] + \"/\" + filename[4:6] + \"/\" + filename[6:8] for filename in diff_file_name_list]\n",
    "print(\"{0}日分のデータが未収集\".format(len(hd_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jcd_list =  [\"桐　生\", \"戸　田\", \"江戸川\", \"平和島\", \"多摩川\", \"浜名湖\", \"蒲　郡\", \"常　滑\",\n",
    "                \"　津　\", \"三　国\", \"びわこ\", \"住之江\", \"尼　崎\", \"鳴　門\", \"丸　亀\", \"児　島\",\n",
    "                \"宮　島\", \"徳　山\", \"下　関\", \"若　松\", \"芦　屋\", \"福　岡\", \"唐　津\", \"大　村\"\n",
    "            ]\n",
    "\n",
    "for hd in hd_list:\n",
    "    print(\"{0} のデータをクロール中\".format(hd))\n",
    "\n",
    "    # 1日単位でデータを集めてファイルに保存する\n",
    "    today_race_df_list = []\n",
    "\n",
    "    for jcd in tqdm(jcd_list):\n",
    "        for i in range(1, 13):\n",
    "            rno = str(i) + \"R\"\n",
    "\n",
    "            # その日レースがない場所は飛ばすためのtry-except         \n",
    "            try:\n",
    "                # 色々なkeyに対してクロールして特定のレースの情報がまとまったdfを作る\n",
    "                raceResult_url = make_url(\"beforeinfo\", rno, jcd, hd)\n",
    "\n",
    "                # パース\n",
    "                soup = html_parser(raceResult_url)\n",
    "\n",
    "                # 対象サイトをcrawl\n",
    "                race_information_df = scrape_beforeinfo(soup, rno, jcd, hd)\n",
    "                race_information_df = race_information_df.set_index([\"date\", \"venue\", \"raceNumber\", \"枠\"])\n",
    "\n",
    "                # 今回のレースのデータを本日のデータを集めたリストに格納\n",
    "                today_race_df_list.append(race_information_df)\n",
    "\n",
    "            except IndexError:\n",
    "                # print(hd + \" \" + jcd + rno +\"データなし\")\n",
    "                pass\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            except ValueError:\n",
    "                # late startの場合、枠番を書く場所がないのでvalue errorになる。とりあえず外しておく\n",
    "                pass\n",
    "\n",
    "    # 本日のレースデータを集めたリストをdfに変換\n",
    "    today_race_df = pd.concat(today_race_df_list, axis = 0)\n",
    "\n",
    "    # pickleファイルで保存\n",
    "    today_race_df.to_pickle('../../../data/crawledData/exhibition_mod/{0}.pkl'.format(\"\".join(hd.split(\"/\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>exhibition_cource</th>\n",
       "      <th>exhibition_start_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>raceNumber</th>\n",
       "      <th>枠</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">2020-11-24</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">江戸川</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>F.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">若　松</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">12</th>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>F.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               exhibition_cource exhibition_start_time\n",
       "date       venue raceNumber 枠                                         \n",
       "2020-11-24 江戸川   1          1                  1                   .08\n",
       "                            2                  2                   .06\n",
       "                            3                  3                  F.18\n",
       "                            4                  4                  F.11\n",
       "                            5                  5                  F.01\n",
       "...                                          ...                   ...\n",
       "           若　松   12         2                  2                  F.06\n",
       "                            3                  3                   .25\n",
       "                            4                  4                   .11\n",
       "                            5                  5                   .29\n",
       "                            6                  6                   .04\n",
       "\n",
       "[846 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ファイル内容確認用\n",
    "df = pd.read_pickle('../../../data/crawledData/exhibition_mod/20201124.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://boatrace.jp/owpc/pc/race/raceresult?rno=9&jcd=24&hd=20210331\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scrape_raceresult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fe1ee0618a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 対象サイトをcrawl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrace_information_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_raceresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mrace_information_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrace_information_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"venue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raceNumber\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"枠\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mrace_information_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scrape_raceresult' is not defined"
     ]
    }
   ],
   "source": [
    "# crawlerの動きを確認する用\n",
    "\n",
    "crawl_key = \"raceresult\"\n",
    "jcd =  \"大　村\"\n",
    "hd = \"2021/03/31\"\n",
    "rno = \"9R\"\n",
    "\n",
    "raceResult_url = make_url(crawl_key, rno, jcd, hd)\n",
    "print(raceResult_url)\n",
    "\n",
    "# パース\n",
    "soup = html_parser(raceResult_url)\n",
    "\n",
    "# 対象サイトをcrawl\n",
    "race_information_df = scrape_raceresult(soup, rno, jcd, hd)\n",
    "race_information_df = race_information_df.set_index([\"date\", \"venue\", \"raceNumber\", \"枠\"])\n",
    "race_information_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_information_df[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
